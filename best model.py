# -*- coding: utf-8 -*-
"""
Created on Tue May 14 11:55:53 2024

@author: SAI SANJANA.KOTHA
"""

##################### Importing necessary libraries  #########################################

import pandas as pd
import os
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
import joblib
from matplotlib import pyplot as plt
import seaborn as sns
from feature_engine.outliers import Winsorizer

from sklearn.pipeline import Pipeline
import pickle, joblib

# import statsmodels.formula.api as smf
import statsmodels.api as sm
from sklearn.model_selection import train_test_split # train and test 
 
# import pylab as pl
from sklearn import metrics
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.metrics import roc_curve
from sklearn.metrics import classification_report



######################  Load the offline data into Database  ##################################
df = pd.read_csv('/Users/SAI SANJANA.KOTHA/Downloads/Data Set (22)/Machine Downtime.csv')
print('Data loaded successfully.')
print(df.head())
print(df.info())
print(df.columns)

df['Downtime' ].value_counts()

df.describe()

df.Downtime

######################### Business Moment Decision  #############################################

numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns
moments = {}
for col in numerical_cols:
    moments[col] = {
        'Mean': df[col].mean(),
        'Variance': df[col].var(),
        'Skewness': df[col].skew(),
        'Kurtosis': df[col].kurt()
    }

# Print or store results for each variable separately
for col, stats in moments.items():
    print(f"Stats for column '{col}':")
    for stat, value in stats.items():
        print(f"{stat}: {value}")
    print()  # Empty line for clarity

########################## Using Auto EDA for cross verification #####################

#pip install sweetviz
import sweetviz as sv
s = sv.analyze(df)
s.show_html()

# Insights from AUTOEDA:
    
# No duplicates found in the dataset.
# Imputation required as there are missing values.


############################# Datapreprocessing  ##########################################################
    
#Drop columns "DATE"
df.drop(columns=['Date'], inplace=True)
df
df.info



# Seperating input and output variables 
x = pd.DataFrame(df.iloc[:,:-1])
y = pd.DataFrame(df.iloc[ : ,-1:])
x
y

# Segregating Non-Numeric features
categorical_features = x.select_dtypes(include = ['object']).columns
print(categorical_features)


# Segregating Numeric features

numeric_features = x.select_dtypes(exclude = ['object']).columns
print(numeric_features)

############ Imputation to handle missing values #################################

###########  MinMaxScaler to scale the data  ######################################

num_pipeline = Pipeline(steps = [('impute', SimpleImputer(strategy = 'mean')),('scale',MinMaxScaler())])

###########  Encoding - One Hot Encoder to convert Categorical data to Numeric values   ############

# Categorical features

encoding_pipeline = Pipeline( [('onehot', OneHotEncoder(sparse_output = False))]) #(sparse_output = Flase) dosent give output as sparse_matrix 


''' Creating a transformation of variable with ColumnTransformer()
 Using ColumnTransfer to transform the columns of an array or pandas DataFrame. 
 This estimator allows different columns or column subsets of the input to be
 transformed separately and the features generated by each transformer will
 be concatenated to form a single feature space.'''

preprocessor = ColumnTransformer(transformers = [('num', num_pipeline, numeric_features), ('categorical', encoding_pipeline, categorical_features)])

imp_enc_scale = preprocessor.fit(x)

#### Save the imputation model using joblib

joblib.dump(imp_enc_scale, 'imp_enc_scale')

os.getcwd()

X = pd.DataFrame(imp_enc_scale.transform(x), columns = imp_enc_scale.get_feature_names_out())

X.describe()
X

### Outlier Analysis
# Multiple boxplots in a single visualization.
# Columns with larger scales affect other columns. 
# Below code ensures each column gets its own y-axis.
# pandas plot() function with parameters kind = 'box' and subplots = True

X.iloc[:,:].columns

### Outlier Detection ### 
data = ['num__Hydraulic_Pressure(bar)', 'num__Coolant_Pressure(bar)',
       'num__Air_System_Pressure(bar)', 'num__Coolant_Temperature',
       'num__Hydraulic_Oil_Temperature(°C)',
       'num__Spindle_Bearing_Temperature(°C)', 'num__Spindle_Vibration(µm)',
       'num__Tool_Vibration(µm)', 'num__Spindle_Speed(RPM)',
       'num__Voltage(volts)', 'num__Torque(Nm)', 'num__Cutting(kN)']

# Create boxplots for each column

plt.figure(figsize=(16, 8))
X[data].boxplot()
plt.title('Boxplot of Machine Downtime')
plt.xticks(rotation = 45, ha='right')  # Rotate and align x-axis labels to the right
plt.ylabel('Values')
plt.xlabel('Columns')
plt.show()


#### Outlier analysis: Columns 'months_loan_duration', 'amount', and 'age' are contin

winsor = Winsorizer(capping_method = 'iqr', # choose  IQR rule boundaries or gaussian for mean and std
                          tail = 'both', # cap left, right or both tails 
                          fold = 1.5,
                          variables =['num__Hydraulic_Pressure(bar)', 'num__Coolant_Pressure(bar)',
                                 'num__Air_System_Pressure(bar)', 'num__Coolant_Temperature',
                                 'num__Hydraulic_Oil_Temperature(°C)',
                                 'num__Spindle_Bearing_Temperature(°C)', 'num__Spindle_Vibration(µm)',
                                 'num__Tool_Vibration(µm)', 'num__Spindle_Speed(RPM)',
                                 'num__Voltage(volts)', 'num__Torque(Nm)', 'num__Cutting(kN)'] )

outlier = winsor.fit(X[['num__Hydraulic_Pressure(bar)', 'num__Coolant_Pressure(bar)',
       'num__Air_System_Pressure(bar)', 'num__Coolant_Temperature',
       'num__Hydraulic_Oil_Temperature(°C)',
       'num__Spindle_Bearing_Temperature(°C)', 'num__Spindle_Vibration(µm)',
       'num__Tool_Vibration(µm)', 'num__Spindle_Speed(RPM)',
       'num__Voltage(volts)', 'num__Torque(Nm)', 'num__Cutting(kN)']])

X[['num__Hydraulic_Pressure(bar)', 'num__Coolant_Pressure(bar)',
       'num__Air_System_Pressure(bar)', 'num__Coolant_Temperature',
       'num__Hydraulic_Oil_Temperature(°C)',
       'num__Spindle_Bearing_Temperature(°C)', 'num__Spindle_Vibration(µm)',
       'num__Tool_Vibration(µm)', 'num__Spindle_Speed(RPM)',
       'num__Voltage(volts)', 'num__Torque(Nm)', 'num__Cutting(kN)']] = outlier.transform(X[['num__Hydraulic_Pressure(bar)', 'num__Coolant_Pressure(bar)',
              'num__Air_System_Pressure(bar)', 'num__Coolant_Temperature',
              'num__Hydraulic_Oil_Temperature(°C)',
              'num__Spindle_Bearing_Temperature(°C)', 'num__Spindle_Vibration(µm)',
              'num__Tool_Vibration(µm)', 'num__Spindle_Speed(RPM)',
              'num__Voltage(volts)', 'num__Torque(Nm)', 'num__Cutting(kN)'
]])
                                                                                                     
X

y['Downtime' ].value_counts()


X.to_csv('Input_variables.csv', index=False)
os.getcwd()

# Output variable as .to_csv
y.to_csv('Output_variables.csv', index=False)
os.getcwd()
              
# recreate boxplots for each column after outlier treatment

plt.figure(figsize=(16, 8))
X[data].boxplot()
plt.title('Boxplot of Machine Downtime')
plt.xticks(rotation = 45, ha='right')  # Rotate and align x-axis labels to the right
plt.ylabel('downtime')
plt.xlabel('Columns')
plt.show()


# Save the winsorizer model 

joblib.dump(outlier, 'winsor')
os.getcwd()

#Encoding the target variable:
    
from sklearn.preprocessing import LabelEncoder

# Assuming y is your categorical target variable DataFrame
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y['Downtime'])

# Convert back to DataFrame if needed
Y = pd.DataFrame(y_encoded, columns=['Encoded_Downtime'])
Y
--------------------------------------------------------------------------------------------------------------
#splitting the data into train and test sets
X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)
X_train,X_test,Y_train,Y_test

------------------------------------------------------------------------------------------------------------------
DECISION TREE      DECISION TREE       DECISION TREE        DECISION TREE       DECISION TREE    DECISION TREE
------------------------------------------------------------------------------------------------------------------

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score

############ Splitting the data into training and testing sets ################

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Initialize the decision tree classifier 
dt_classifier = DecisionTreeClassifier(random_state=42)

# Training the model 
dt_classifier.fit(X_train, Y_train)

# Testing the model
y_pred_train = dt_classifier.predict(X_train)
train_accuracy = accuracy_score(Y_train, y_pred_train)
print("Training Accuracy (before tuning):", train_accuracy)

y_pred_test = dt_classifier.predict(X_test)
test_accuracy = accuracy_score(Y_test, y_pred_test)
print("Testing Accuracy (before tuning):", test_accuracy)

# Hyperparameter tuning

param_grid = {
    'criterion': ['gini', 'entropy'],
    'max_depth': [ 5 ],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, cv=5)
grid_search.fit(X_train, Y_train)

# Get the best hyperparameters
best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

# Get the best model
best_dt_classifier = grid_search.best_estimator_
best_dt_classifier
# Testing the best model
y_pred_train_best = best_dt_classifier.predict(X_train)
train_accuracy_best = accuracy_score(Y_train, y_pred_train_best)
print("Training Accuracy (after tuning):", train_accuracy_best)

y_pred_test_best = best_dt_classifier.predict(X_test)
test_accuracy_best = accuracy_score(Y_test, y_pred_test_best)
print("Testing Accuracy (after tuning):", test_accuracy_best)

from sklearn.metrics import classification_report, roc_auc_score

# Classification report
class_report = classification_report(Y_test, y_pred_test_best)
print("Classification Report:")
print(class_report)

# F1 score
f1_score_best = f1_score(Y_test, y_pred_test_best, average='weighted')
print("F1 Score (after tuning):", f1_score_best)

# Recall
recall_best = recall_score(Y_test, y_pred_test_best, average='weighted')
print("Recall (after tuning):", recall_best)

# Precision
precision_best = precision_score(Y_test, y_pred_test_best, average='weighted')
print("Precision (after tuning):", precision_best)


# ROC AUC score
roc_auc_best = roc_auc_score(Y_test, best_dt_classifier.predict_proba(X_test)[:, 1], average='weighted')
print("ROC AUC Score (after tuning):", roc_auc_best)


''' 
observation from the above values of  F1, Precision, ROC_AUC, Recall ,
 classification report , accuracy:
     

The results indicate that the decision tree model performs reasonably well after tuning:

Training Accuracy: After tuning, the training accuracy is 97.8%, 
indicating that the model correctly classifies 97.8% of the instances 
in the training data.

Testing Accuracy: The testing accuracy is 97.4%, indicating that the model 
correctly classifies 97.4% of the instances in the testing data.

Classification Report: The classification report provides additional insights 
into the model's performance for each class. The precision, recall, and F1-score are 
high for both classes (0 and 1), indicating that the model performs well in terms of 
both positive and negative instances.

F1 Score: The weighted average F1-score is 0.974, which is a harmonic mean of precision 
and recall. It is a balanced measure of the model's accuracy.

Recall and Precision: Both recall and precision are high (97.4% and 97.4%, respectively),
 indicating that the model effectively captures the positive instances while minimizing 
 false positives.
 
ROC AUC Score: The ROC AUC score is 0.985, which indicates that the model has good 
discriminatory power in distinguishing between the positive and negative classes.Overall, 
these results suggest that the decision tree model performs well after tuning and is a good
 fit for the given classification task'''.



#Save the Model: 
import joblib
joblib.dump(best_dt_classifier, 'decision_tree_model.joblib')

os.getcwd()

#performance plot for decision tree:

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt
pip install --upgrade scikit-learn

# Plot confusion matrix
plt.figure(figsize=(8, 6))
cm = confusion_matrix(Y_test, y_pred_test_best)
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.show()

from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt

# Assuming best_dt_classifier, X_test, and Y_test are defined
y_scores = best_dt_classifier.predict_proba(X_test)[:, 1]  # predicted probabilities of class 1
fpr, tpr, thresholds = roc_curve(Y_test, y_scores)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label='ROC Curve (AUC = {:.2f})'.format(roc_auc_score(Y_test, y_scores)))
plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Guessing')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()
plt.grid(True)
plt.show()

# **Added code for visualization**

# Confusion Matrix
plt.figure(figsize=(10, 8))
sns.heatmap(confusion_matrix(Y_test, y_pred_test_best), annot=True, cmap='Blues')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

# ROC Curve
plt.figure(figsize=(10, 8))
fpr, tpr, _ = roc_curve(Y_test, best_dt_classifier.predict_proba(X_test)[:, 1])
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_best)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

#learning curve
import numpy as np
from sklearn.model_selection import learning_curve
def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):
    plt.figure()
    plt.title(title)
    if ylim is not None:
        plt.ylim(*ylim)
    plt.xlabel("Training examples")
    plt.ylabel("Score")
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    plt.grid()

    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1,
                     color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="g")
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r",
             label="Training score")
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g",
             label="Cross-validation score")
    plt.legend(loc="best")

    # Adjust y-limits based on the training and testing accuracy
    plt.ylim(0.8, 1.05)

    plt.show()

# Plot learning curve
plot_learning_curve(best_dt_classifier, "Learning Curve", X_train, Y_train, cv=5)

'''Decision tree helps in interpretability(easy to understand .
 Decision trees can capture non-linear relationships between features and the target variable.
 Decision trees can handle missing values in the data without requiring imputation or preprocessing steps.
 Decision trees are robust to outliers in the data
 Decision trees are scalable(handle large data sets) and they are versatile(can have different data types and handle both regression and classification)
 Decision trees serve as fundamental building blocks for ensemble methods such as Random Forests, Gradient Boosting Machines, and AdaBoost.
 Decision tree helps in Overfitting Control'''
 
 